{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up PyStan demos on Google Colab with model caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up demos with caching, user needs to upload compiled models to github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import used libraries\n",
    "import os\n",
    "from stan_colab_utils import StanModel, install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "install(\"pystan\")\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "eight_schools_path =            \"models/eight_schools/8schools.stan\"\n",
    "eight_schools_data_path =       \"models/eight_schools/8schools.data.R\"\n",
    "eight_schools_model_cache =     \"models/eight_schools/8schools_model.gz\"\n",
    "eight_schools_model_fit_cache = \"models/eight_schools/8schools_model_fit.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-schools model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data {\n",
      "    int<lower=0> J; // number of schools\n",
      "    vector[J] y; // estimated treatment effects\n",
      "    vector<lower=0>[J] sigma; // s.e. of effect estimates\n",
      "}\n",
      "parameters {\n",
      "    real mu;\n",
      "    real<lower=0> tau;\n",
      "    vector[J] eta;\n",
      "}\n",
      "transformed parameters {\n",
      "    vector[J] theta;\n",
      "    theta = mu + tau * eta;\n",
      "}\n",
      "model {\n",
      "    eta ~ normal(0, 1);\n",
      "    y ~ normal(theta, sigma);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(eight_schools_path, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-schools data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('J', array(8)),\n",
       "             ('y', array([28,  8, -3,  7, -1,  1, 18, 12])),\n",
       "             ('sigma', array([15, 10, 16, 11,  9, 11, 10, 18]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stan_data = pystan.read_rdump(eight_schools_data_path)\n",
    "stan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_seed = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile model and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_b9d9d4eb1cc460053ac2b8a9dd68028e NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.9 s\n",
      "Wall time: 1.62 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%time stan_model = pystan.StanModel(file=eight_schools_path)\n",
    "%time fit = stan_model.sampling(data=stan_data, seed=stan_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_b9d9d4eb1cc460053ac2b8a9dd68028e.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu         8.07    0.12   5.22  -2.18   4.84   8.03  11.25  18.29   2044    1.0\n",
      "tau        6.43    0.14   5.39   0.27   2.42   5.09   8.98  20.16   1470    1.0\n",
      "eta[1]     0.37    0.02   0.94  -1.49  -0.25    0.4   1.03   2.13   3701    1.0\n",
      "eta[2]  -3.7e-3    0.01   0.91  -1.83   -0.6  -0.02    0.6   1.82   3940    1.0\n",
      "eta[3]    -0.18    0.01   0.93  -2.04  -0.78  -0.16   0.43   1.69   4364    1.0\n",
      "eta[4]    -0.05    0.01   0.87  -1.75  -0.61  -0.05   0.51   1.71   4077    1.0\n",
      "eta[5]    -0.32    0.01   0.85  -1.97  -0.88  -0.34   0.23    1.4   3565    1.0\n",
      "eta[6]    -0.22    0.01   0.89  -1.97  -0.81  -0.24   0.38   1.57   4363    1.0\n",
      "eta[7]     0.32    0.01   0.88  -1.46  -0.24   0.33   0.91   1.98   4159    1.0\n",
      "eta[8]     0.04    0.01   0.95  -1.77  -0.61   0.03   0.68    1.9   4200    1.0\n",
      "theta[1]  11.35    0.16    8.4  -2.42   5.88  10.07   15.7  31.23   2719    1.0\n",
      "theta[2]    8.1     0.1   6.52  -5.01   4.09   8.01  12.09  21.59   4382    1.0\n",
      "theta[3]    6.4    0.13   7.72 -11.21   2.46    6.9  11.04  20.39   3776    1.0\n",
      "theta[4]   7.67    0.09   6.33  -5.15   3.83   7.67  11.57  20.37   4464    1.0\n",
      "theta[5]   5.56     0.1   6.37  -8.59   1.75   6.01   9.85  16.84   4037    1.0\n",
      "theta[6]    6.2    0.11   6.82  -8.07   2.39    6.5   10.6  18.94   3742    1.0\n",
      "theta[7]  10.51    0.12   6.61  -1.26   6.06   9.95   14.4  25.38   3189    1.0\n",
      "theta[8]   8.43    0.13   7.88  -7.21   3.83   8.18  12.78  25.24   3788    1.0\n",
      "lp__      -4.93    0.07   2.66 -11.05  -6.54  -4.63  -3.04  -0.42   1369    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Tue Aug 28 14:07:29 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stan_colab_utils import save, read\n",
    "if not os.path.exists(eight_schools_model_cache):\n",
    "    save(eight_schools_model_cache, stan_model)\n",
    "if not os.path.exists(eight_schools_model_fit_cache):\n",
    "    save(eight_schools_model_fit_cache, [stan_model, fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file from cache (or compile if not found) and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 ms\n",
      "Wall time: 1.53 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%time stan_model2 = StanModel(file=eight_schools_path, cache_path=eight_schools_model_cache)\n",
    "%time fit2 = stan_model2.sampling(data=stan_data, seed=stan_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_b9d9d4eb1cc460053ac2b8a9dd68028e.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu         8.07    0.12   5.22  -2.18   4.84   8.03  11.25  18.29   2044    1.0\n",
      "tau        6.43    0.14   5.39   0.27   2.42   5.09   8.98  20.16   1470    1.0\n",
      "eta[1]     0.37    0.02   0.94  -1.49  -0.25    0.4   1.03   2.13   3701    1.0\n",
      "eta[2]  -3.7e-3    0.01   0.91  -1.83   -0.6  -0.02    0.6   1.82   3940    1.0\n",
      "eta[3]    -0.18    0.01   0.93  -2.04  -0.78  -0.16   0.43   1.69   4364    1.0\n",
      "eta[4]    -0.05    0.01   0.87  -1.75  -0.61  -0.05   0.51   1.71   4077    1.0\n",
      "eta[5]    -0.32    0.01   0.85  -1.97  -0.88  -0.34   0.23    1.4   3565    1.0\n",
      "eta[6]    -0.22    0.01   0.89  -1.97  -0.81  -0.24   0.38   1.57   4363    1.0\n",
      "eta[7]     0.32    0.01   0.88  -1.46  -0.24   0.33   0.91   1.98   4159    1.0\n",
      "eta[8]     0.04    0.01   0.95  -1.77  -0.61   0.03   0.68    1.9   4200    1.0\n",
      "theta[1]  11.35    0.16    8.4  -2.42   5.88  10.07   15.7  31.23   2719    1.0\n",
      "theta[2]    8.1     0.1   6.52  -5.01   4.09   8.01  12.09  21.59   4382    1.0\n",
      "theta[3]    6.4    0.13   7.72 -11.21   2.46    6.9  11.04  20.39   3776    1.0\n",
      "theta[4]   7.67    0.09   6.33  -5.15   3.83   7.67  11.57  20.37   4464    1.0\n",
      "theta[5]   5.56     0.1   6.37  -8.59   1.75   6.01   9.85  16.84   4037    1.0\n",
      "theta[6]    6.2    0.11   6.82  -8.07   2.39    6.5   10.6  18.94   3742    1.0\n",
      "theta[7]  10.51    0.12   6.61  -1.26   6.06   9.95   14.4  25.38   3189    1.0\n",
      "theta[8]   8.43    0.13   7.88  -7.21   3.83   8.18  12.78  25.24   3788    1.0\n",
      "lp__      -4.93    0.07   2.66 -11.05  -6.54  -4.63  -3.04  -0.42   1369    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Tue Aug 28 14:08:26 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(fit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read sampling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59 ms\n",
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For slow models, it might be a good idea to save presampled data\n",
    "%time stan_model3, fit3 = read(eight_schools_model_fit_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_b9d9d4eb1cc460053ac2b8a9dd68028e.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "           mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "mu         8.07    0.12   5.22  -2.18   4.84   8.03  11.25  18.29   2044    1.0\n",
      "tau        6.43    0.14   5.39   0.27   2.42   5.09   8.98  20.16   1470    1.0\n",
      "eta[1]     0.37    0.02   0.94  -1.49  -0.25    0.4   1.03   2.13   3701    1.0\n",
      "eta[2]  -3.7e-3    0.01   0.91  -1.83   -0.6  -0.02    0.6   1.82   3940    1.0\n",
      "eta[3]    -0.18    0.01   0.93  -2.04  -0.78  -0.16   0.43   1.69   4364    1.0\n",
      "eta[4]    -0.05    0.01   0.87  -1.75  -0.61  -0.05   0.51   1.71   4077    1.0\n",
      "eta[5]    -0.32    0.01   0.85  -1.97  -0.88  -0.34   0.23    1.4   3565    1.0\n",
      "eta[6]    -0.22    0.01   0.89  -1.97  -0.81  -0.24   0.38   1.57   4363    1.0\n",
      "eta[7]     0.32    0.01   0.88  -1.46  -0.24   0.33   0.91   1.98   4159    1.0\n",
      "eta[8]     0.04    0.01   0.95  -1.77  -0.61   0.03   0.68    1.9   4200    1.0\n",
      "theta[1]  11.35    0.16    8.4  -2.42   5.88  10.07   15.7  31.23   2719    1.0\n",
      "theta[2]    8.1     0.1   6.52  -5.01   4.09   8.01  12.09  21.59   4382    1.0\n",
      "theta[3]    6.4    0.13   7.72 -11.21   2.46    6.9  11.04  20.39   3776    1.0\n",
      "theta[4]   7.67    0.09   6.33  -5.15   3.83   7.67  11.57  20.37   4464    1.0\n",
      "theta[5]   5.56     0.1   6.37  -8.59   1.75   6.01   9.85  16.84   4037    1.0\n",
      "theta[6]    6.2    0.11   6.82  -8.07   2.39    6.5   10.6  18.94   3742    1.0\n",
      "theta[7]  10.51    0.12   6.61  -1.26   6.06   9.95   14.4  25.38   3189    1.0\n",
      "theta[8]   8.43    0.13   7.88  -7.21   3.83   8.18  12.78  25.24   3788    1.0\n",
      "lp__      -4.93    0.07   2.66 -11.05  -6.54  -4.63  -3.04  -0.42   1369    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Tue Aug 28 14:07:29 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(fit3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook date: 2018-08-28 \n",
      "\n",
      "python 3.7.0 | packaged by conda-forge | (default, Jul 13 2018, 23:54:23) [MSC v.1900 64 bit (AMD64)]\n",
      "numpy 1.15.0\n",
      "pystan 2.18.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "print(\"Notebook date:\", datetime.now().date(), \"\\n\")\n",
    "for tool in [sys, np, pystan]:\n",
    "    if tool.__name__ == 'sys':\n",
    "        print(\"python\", tool.version)\n",
    "    else:\n",
    "        print(tool.__name__, tool.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
